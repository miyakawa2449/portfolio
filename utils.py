"""
Utility Functions - ä¸€èˆ¬çš„ãªãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•°
"""
import bleach
import markdown
import re
from markupsafe import Markup
from flask import current_app

def sanitize_html(content):
    """HTMLã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ã‚µãƒ‹ã‚¿ã‚¤ã‚º"""
    allowed_tags = ['p', 'br', 'strong', 'em', 'u', 'ol', 'ul', 'li', 'a', 'h1', 'h2', 'h3', 'h4', 'h5', 'h6']
    allowed_attributes = {'a': ['href', 'title']}
    return bleach.clean(content, tags=allowed_tags, attributes=allowed_attributes, strip=True)

def clear_ogp_cache():
    """OGPã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¯ãƒªã‚¢ã™ã‚‹é–¢æ•°"""
    from app import ogp_cache
    ogp_cache.clear()
    current_app.logger.info("ğŸ—‘ï¸ OGP cache cleared")

def perform_search(query, search_filter='all'):
    """ã‚µã‚¤ãƒˆå†…æ¤œç´¢ã‚’å®Ÿè¡Œ"""
    from models import Article, Project, db
    from sqlalchemy import select, or_
    
    if not query or len(query.strip()) < 2:
        return {'articles': [], 'projects': [], 'total': 0}
    
    query = query.strip()
    results = {'articles': [], 'projects': [], 'total': 0}
    
    try:
        if search_filter in ['all', 'articles']:
            # è¨˜äº‹æ¤œç´¢ï¼ˆLIKEæ¼”ç®—å­ä½¿ç”¨ï¼‰
            article_query = select(Article).where(
                Article.status == 'published'
            ).where(
                or_(
                    Article.title.like(f'%{query}%'),
                    Article.summary.like(f'%{query}%'),
                    Article.content.like(f'%{query}%')
                )
            ).order_by(Article.published_at.desc())
            
            articles = db.session.execute(article_query).scalars().all()
            results['articles'] = articles
        
        if search_filter in ['all', 'projects']:
            # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ¤œç´¢
            project_query = select(Project).where(
                Project.status == 'active'
            ).where(
                or_(
                    Project.title.like(f'%{query}%'),
                    Project.description.like(f'%{query}%'),
                    Project.summary.like(f'%{query}%')
                )
            ).order_by(Project.created_at.desc())
            
            projects = db.session.execute(project_query).scalars().all()
            results['projects'] = projects
        
        results['total'] = len(results['articles']) + len(results['projects'])
        current_app.logger.info(f"ğŸ” Search completed: query='{query}', filter='{search_filter}', total={results['total']}")
        
    except Exception as e:
        current_app.logger.error(f"âŒ Search error: {e}")
        results = {'articles': [], 'projects': [], 'total': 0, 'error': str(e)}
    
    return results

def process_markdown(text):
    """Markdownãƒ†ã‚­ã‚¹ãƒˆã‚’HTMLã«å¤‰æ›ã™ã‚‹é–¢æ•°ï¼ˆSNSåŸ‹è¾¼è‡ªå‹•æ¤œå‡ºä»˜ãï¼‰"""
    if not text:
        return ''
    
    # Markdownã®æ‹¡å¼µæ©Ÿèƒ½ã‚’è¨­å®š
    md = markdown.Markdown(
        extensions=['extra', 'codehilite', 'toc', 'nl2br'],
        extension_configs={
            'codehilite': {
                'css_class': 'highlight',
                'use_pygments': False
            }
        },
        tab_length=2  # ã‚¿ãƒ–é•·ã‚’çŸ­ãè¨­å®š
    )
    
    # Markdownã‚’HTMLã«å¤‰æ›
    html = md.convert(text)
    
    # ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã®ãŸã‚HTMLã‚’ã‚µãƒ‹ã‚¿ã‚¤ã‚ºï¼ˆSNSåŸ‹è¾¼ç”¨ã‚¿ã‚°ã‚’è¿½åŠ ï¼‰
    allowed_tags = [
        'h1', 'h2', 'h3', 'h4', 'h5', 'h6',
        'p', 'br', 'strong', 'em', 'u', 'del',
        'ul', 'ol', 'li', 'blockquote', 'pre', 'code',
        'a', 'img', 'table', 'thead', 'tbody', 'tr', 'th', 'td',
        # SNSåŸ‹è¾¼ç”¨ã‚¿ã‚°
        'div', 'iframe', 'script', 'blockquote', 'noscript'
    ]
    allowed_attributes = {
        'a': ['href', 'title', 'target', 'rel'],
        'img': ['src', 'alt', 'title', 'width', 'height'],
        'code': ['class'],
        'pre': ['class'],
        'h1': ['id'], 'h2': ['id'], 'h3': ['id'], 'h4': ['id'], 'h5': ['id'], 'h6': ['id'],
        # SNSåŸ‹è¾¼ç”¨å±æ€§
        'div': ['class', 'id', 'style', 'data-href', 'data-width', 'data-instgrm-permalink'],
        'iframe': ['src', 'width', 'height', 'frameborder', 'allow', 'allowfullscreen', 'title', 'style'],
        'script': ['src', 'async', 'defer', 'charset', 'crossorigin'],
        'blockquote': ['class', 'style', 'data-instgrm-permalink'],
        'noscript': []
    }
    
    # SNSåŸ‹è¾¼HTMLãŒã‚ã‚‹å ´åˆã¯bleachã‚’é©ç”¨ã—ãªã„ï¼ˆå®‰å…¨ãªHTMLã®ãŸã‚ï¼‰
    if any(cls in html for cls in ['sns-embed', 'youtube-embed', 'twitter-embed', 'instagram-embed', 'facebook-embed', 'threads-embed']):
        clean_html = html
    else:
        # é€šå¸¸ã®Markdownã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®ã¿ã‚µãƒ‹ã‚¿ã‚¤ã‚º
        clean_html = bleach.clean(html, tags=allowed_tags, attributes=allowed_attributes)
    
    # è¦‹å‡ºã—ã«ã‚¢ãƒ³ã‚«ãƒ¼IDã‚’è¿½åŠ 
    clean_html = add_heading_anchors(clean_html)
    
    return Markup(clean_html)

def generate_ogp_data(title, description=None, image_url=None, url=None):
    """OGPãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã™ã‚‹é–¢æ•°"""
    ogp_data = {
        'title': title,
        'description': description or 'è¨˜äº‹ã®è©³ç´°ã¯ã“ã¡ã‚‰ã‚’ã”è¦§ãã ã•ã„',
        'image': image_url,
        'url': url
    }
    return ogp_data

def generate_table_of_contents(markdown_content):
    """Markdownã‹ã‚‰ç›®æ¬¡ã‚’ç”Ÿæˆ"""
    import re
    
    if not markdown_content:
        return None
    
    # è¦‹å‡ºã—ã‚’æŠ½å‡ºã™ã‚‹ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆ# ## ### #### ##### ######ï¼‰
    heading_pattern = r'^(#{1,6})\s+(.+)'
    headings = []
    heading_counter = 0
    
    for line_num, line in enumerate(markdown_content.split('\n'), 1):
        line = line.strip()
        match = re.match(heading_pattern, line)
        if match:
            heading_counter += 1  # è¦‹å‡ºã—ã®é †ç•ªã‚’ã‚«ã‚¦ãƒ³ãƒˆ
            level = len(match.group(1))  # # ã®æ•°
            title = match.group(2).strip()
            
            # ã‚¢ãƒ³ã‚«ãƒ¼ç”¨ã®IDã‚’ç”Ÿæˆï¼ˆæ—¥æœ¬èªå¯¾å¿œï¼‰
            anchor_id = re.sub(r'[^\w\-_\u3040-\u309F\u30A0-\u30FF\u4E00-\u9FAF]', '-', title.lower())
            anchor_id = re.sub(r'-+', '-', anchor_id).strip('-')
            anchor_id = f"heading-{heading_counter}-{anchor_id}" if anchor_id else f"heading-{heading_counter}"
            
            headings.append({
                'level': level,
                'title': title,
                'anchor': anchor_id,
                'line': line_num
            })
    
    return headings if headings else None

def add_heading_anchors(html_content):
    """HTMLè¦‹å‡ºã—ã«ã‚¢ãƒ³ã‚«ãƒ¼IDã‚’è¿½åŠ ï¼ˆç›®æ¬¡ã¨ä¸€è‡´ã•ã›ã‚‹ï¼‰"""
    if not html_content:
        return html_content
    
    import re
    from bs4 import BeautifulSoup
    
    try:
        soup = BeautifulSoup(html_content, 'html.parser')
        heading_counter = 0
        
        # h1ã€œh6ã‚¿ã‚°ã‚’é †ç•ªã«æ¤œç´¢ã—ã¦IDã‚’è¿½åŠ 
        for heading in soup.find_all(['h1', 'h2', 'h3', 'h4', 'h5', 'h6']):
            heading_counter += 1
            title = heading.get_text().strip()
            
            # ç›®æ¬¡ç”Ÿæˆã¨åŒã˜ãƒ­ã‚¸ãƒƒã‚¯ã§ã‚¢ãƒ³ã‚«ãƒ¼IDã‚’ç”Ÿæˆ
            anchor_id = re.sub(r'[^\w\-_\u3040-\u309F\u30A0-\u30FF\u4E00-\u9FAF]', '-', title.lower())
            anchor_id = re.sub(r'-+', '-', anchor_id).strip('-')
            anchor_id = f"heading-{heading_counter}-{anchor_id}" if anchor_id else f"heading-{heading_counter}"
            
            heading['id'] = anchor_id
            current_app.logger.debug(f"Added anchor: {anchor_id} for heading: {title}")
        
        return str(soup)
        
    except Exception as e:
        current_app.logger.error(f"Error adding heading anchors: {e}")
        return html_content

